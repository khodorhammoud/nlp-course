{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN cheat sheet.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOpSKHIUeowJwKyRmdfPtwP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khodorhammoud/nlp-course/blob/main/CNN_cheat_sheet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4SSYhGfB7Qi"
      },
      "source": [
        "#loading word2vec\r\n",
        "import gensim\r\n",
        "w2v = gensim.models.KeyedVectors.load_word2vec_format('path_to_pretrained_model', binary=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwCBFNRTCGKX"
      },
      "source": [
        "#get the vectorized form of a word/token\r\n",
        "try:\r\n",
        "  sample_vecs.append(w2v[token]) # in case the word doesn't exist in the vocabulary\r\n",
        "except KeyError:\r\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BUn9rvsCnkv"
      },
      "source": [
        "from keras.preprocessing import sequence # A helper module to handle padding input\r\n",
        "from keras.models import Sequential # The base Keras neural network model\r\n",
        "from keras.layers import Dense, Dropout, Activation #The layer objects you’ll pile into the model\r\n",
        "from keras.layers import Conv1D, GlobalMaxPooling1D  # Your convolution layer, and pooling"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaJ-yWd5CvOD"
      },
      "source": [
        "# pad or truncate the data to the desired length\r\n",
        "def pad_trunc(data, maxlen):\r\n",
        "\tnew_data = []\r\n",
        "\t# Create a vector of 0s the length of our word vectors\r\n",
        "\tzero_vector = []\r\n",
        "\tfor _ in range(len(data[0][0])):\r\n",
        "\t\tzero_vector.append(0.0)\r\n",
        "\t\r\n",
        "\tfor sample in tqdm(data):\r\n",
        "\t\tif len(sample) > maxlen:\r\n",
        "\t\t\ttemp = sample[:maxlen]\r\n",
        "\t\telif len(sample) < maxlen:\r\n",
        "\t\t\ttemp = sample\r\n",
        "\t\t\t# Append the appropriate number 0 vectors to the list\r\n",
        "\t\t\tadditional_elems = maxlen - len(sample)\r\n",
        "\t\t\tfor _ in range(additional_elems):\r\n",
        "\t\t\t\ttemp.append(zero_vector)\r\n",
        "\t\telse:\r\n",
        "\t\t\ttemp = sample\r\n",
        "\t\tnew_data.append(temp)\r\n",
        "\treturn new_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtwlN67pC77j"
      },
      "source": [
        "model creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCVdYuwcC1DZ"
      },
      "source": [
        "model = Sequential()\r\n",
        "model.add(Conv1D( # the first layer you add is the convolutional layer\r\n",
        "  filters, # Number of filters you’ll train\r\n",
        "  kernel_size,  # The width of the filters; actual filters will each be a matrix of weights of size: embedding_dims x kernel_size\r\n",
        "  padding='valid', # assume that it's ok for the output to be of smaller domentions than the input \r\n",
        "  activation='relu', # the activation function to use\r\n",
        "  strides=1, # number of tokens to slide by on every new stride\r\n",
        "  input_shape=(maxlen, embedding_dims)) \r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AS8OsnD8Df5l"
      },
      "source": [
        "Model.add() # add the layers of Convolution, max pooling, dense, dropout, activation "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13r4SW7gD1eL"
      },
      "source": [
        "# copiling the model\r\n",
        "model.compile() # choose loss, optimizer and metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iB1ioKTjEEca"
      },
      "source": [
        "# start the training\r\n",
        "model.fit(x_train, y_train,\r\n",
        "  batch_size=batch_size,\r\n",
        "  epochs=epochs,\r\n",
        "  validation_data=(x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_B83phtFELpb"
      },
      "source": [
        "#test your model\r\n",
        "smpl =  tokenize_and_vectorize([(1, \"The sugar is sweet\")])\r\n",
        "smpl = pad_trunc(smpl, maxlen)\r\n",
        "test_vec = np.reshape(smpl, (len(smpl), maxlen, embedding_dims))\r\n",
        "model.predict_classes(test_vec)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}